> https://d2l.ai/chapter_convolutional-modern/cnn-design.html

## 8.8.1. The AnyNet Design Space

В статье рассматривается стратегия разработки нейронок, предложенная `Radosavovic et al., 2020`, которая объединяет сильные стороны проектирования вручную и поиска наилучшей сетки методом [NAS](https://en.wikipedia.org/wiki/Neural_architecture_search)
> Radosavovic, I., Kosaraju, R. P., Girshick, R., He, K., & Dollár, P. (2020). Designing network design spaces. _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_ (pp. 10428–10436).

Шаблон построения CNN:
1. Stem - выполняется начальная обработка изображений посредством сверток с бо'льшим размером ядра. Получает на вход трехканальное изображение в свертку с ядром `3 x 3`, шагом 2 и заданным кол-вом выходных каналов c_0, за которым следует batch нормализация. На выходе получается даунсемплированное (уменьшенное в разрешении) на 2 изображение.
2. Body - состоит из нескольких стадий, каждый из которых формируется блоками сверток. 
   > Блоки отвечают за собственно трансформации исходных данных в репрезентативные объекты, по пути уменьшая разрешение изображений (и увеличивая на четверть пространственное разрешение). 
   
	Первый блок стадии уменьшает (*ResNeXt block with downsampling*), а последующие блоки оставляют неизменной (*ResNeXt block*) размерность. Сначала идет свертка `1 x 1` (понижающая количество каналов на `k_i`), затем свертка `3 x 3` с шагом 1 или 2 (`*`, здесь и уменьшится разрешение изображения, сохранив кол-во каналов) и снова свертка `1 x 1` (`*`, с заданным кол-вом каналов, или исходным в противном случае); для сопоставления размерностей `*` в параллельной ветке преобразований применяется `1 x 1` свертка с шагом 2 и заданным кол-вом каналов. В конце блока трансформированное и исходное (или даунсемплированное `*`) изображения накладываются.
   `*` - в случае даунсемплинга
   `c_i` - кол-во каналов [0,4]
   `g_i` - номер группы [1,4]
   `d_i` - кол-во блоков в стадии [1,4]
   `k_i` - bottleneck ratio [1,4]
   (*для этого пространства сетей у нас будет 17 гиперпараметров, что довольно много*)
   > На примере ImageNet `224x244x3` **body** понизит разрешение до `7 x 7 x c_4`, пройдя через step и 4 стадии: `224/2^5=7` (при условии понижении размерности *везде) 
3. Head - эти объедки проходят **global average pooling** и конвертируются в выходы посредством полносвязного слоя (n) и функции активации (например softmax regressor для многоклассовой классификации)

Этот паттерн характерен для всех базовых сеток, начиная с VGG до ResNeXt.
![[Pasted image 20250101213521.png]]
```python
class AnyNet(d2l.Classifier):
	
	def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):
	    super(AnyNet, self).__init__()
	    self.save_hyperparameters()
	    self.net = nn.Sequential(self.stem(stem_channels))
	    for i, s in enumerate(arch):
	        self.net.add_module(f'stage{i+1}', self.stage(*s))
	    self.net.add_module('head', nn.Sequential(
	        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),
	        nn.LazyLinear(num_classes)))
	    self.net.apply(d2l.init_cnn)

    def stem(self, num_channels):
        return nn.Sequential(
            nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),
            nn.LazyBatchNorm2d(), nn.ReLU())

	def stage(self, depth, num_channels, groups, bot_mul):
	    blk = []
	    for i in range(depth):
	        if i == 0:
	            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,
	                use_1x1conv=True, strides=2))
	        else:
	            blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))
	    return nn.Sequential(*blk)
```

## 8.8.2. Distributions and Parameters of Design Spaces

В общей сложности, если предположить даже то, что каждый гиперпараметр будет бинарный, то получается 2^17 = 131072 комбинаций параметров. Так дело не пойдет, поэтому подход Радосавовича заключался в следующих предположениях: 
- Существуют общие принципы, которым следуют успешные модели и задача заключается в идентификации *распределения* таких моделей
- Нам не нужно полностью тренить модели до схождения, достаточно промежуточных результатов для прослеживания общих тенденций обучения.
- Результаты, полученные на датасете меньшего разрешения (с сопоставимо меньшей сетью: меньшим кол-вом слоков, каналов и т.д.) обобщаются до большего разрешения, что значительно уменьшает кол-во вычислений.
- Этапы могут быть разложены на множители, что поможет сделать выводы о влиянии каждого на качество результата по отдельности и задача оптимизации становится относительно простой.

Мы можем выбрать равномерный семпл из пространства сетей, обучить их и посмотреть на кумулятивное распределение (CDF) ошибок/точности. Если CDF будет будет доминировать (или равняться) другой CDF, то это будет значить что первый превосходит (или не имеет разницы) другой CDF.
![[Pasted image 20250102153224.png]]

Так, если рассмотреть сеть с k_i=k, т.е. одинаковым bottleneck ratio во всех стадиях, то можно увидеть, что этот параметр не влияет на производительность, тем самым мы уменьшаем кол-во комбинаций на 3. То же самое и с размером группы g_i. А вот увеличение кол-ва каналов  c_i и блоков d_i увеличивает точность сети. Таким образом мы уменьшили кол-во комбинаций на 3.

## 8.8.3. RegNet
- полученная сеть AnyNetX_E, которая является результатом этих исследований: 
	- $k_i=k, g_i=g, \forall$ stages i;
	- постепенно увеличивающаяся ширина сети (кол-во каналов $c_i <= c_{i+1}$)
	- и глубина сети ($d_i <= d_{i+1}$)
*А дальше еще интереснее!*
В результате исследований наиболее важными выводами для производительной сети стали:
- ширина сети увеличивается линейно, т.е. $c_j \approx c_0 + c_a * j$. Так мы сократили перебор до выбора слоупов для каждой стадии и сошлись к кусочно-постоянным функциям.
- bottleneck ration k не нужен вообще! (как показали эксперименты)
RegNetX:
- k=1
- g=15
- c_1=32, c_2=80
- d_1=4, d_2=6
```python
class RegNetX32(AnyNet):
    def __init__(self, lr=0.1, num_classes=10):
        stem_channels, groups, bot_mul = 32, 16, 1
        depths, channels = (4, 6), (32, 80)
        super().__init__(
            ((depths[0], channels[0], groups, bot_mul),
             (depths[1], channels[1], groups, bot_mul)),
            stem_channels, lr, num_classes)

RegNetX32().layer_summary((1, 1, 96, 96))

---
Sequential output shape:     torch.Size([1, 32, 48, 48])
Sequential output shape:     torch.Size([1, 32, 24, 24])
Sequential output shape:     torch.Size([1, 80, 12, 12])
Sequential output shape:     torch.Size([1, 10])
```